{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IBPY import IB_PY \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "# A function that gets api information, ticker, date, starting strike and intervals.\n",
    "# The function calculated the stats in the Augen Book\n",
    "def expiration_stats(ticker_, date_, strikes_, ib_whatToShow_):\n",
    "    \"\"\"\n",
    "    This function calculates the stats in the Augen book. \n",
    "    We need these stats to be able to pin down stocks that are good candidate for expiration trading.\n",
    "    The function spits out a tuple of 1 * 3. \n",
    "    \n",
    "    api_ : an object of api_ type to connect to IB. This should be my own api class\n",
    "    ticker_ : ticker of the contract. A string object.\n",
    "    date_ : the date the we are interested in. A datetime object.\n",
    "    strikes_: an arraye of strikes. Sorted numpy array. 1D.\n",
    "    ib_whatToShow_: what to query from ib. could be 'LAST' or 'MIDPOINT' or 'IMPLIED_VOL'. Has to be a string\n",
    "    \"\"\"\n",
    "    api_ = IB_PY()\n",
    "    cont = api_.make_contract(symbol = ticker_, secType = 'STK', currency = 'USD', exchange = 'SMART')\n",
    "    api_.get_historical_data(cont, barSizeSetting_= '1 min', \n",
    "                        durationStr_= '1 D', \n",
    "                        whatToShow_= ib_whatToShow_, \n",
    "                        endDateTime_= date_, \n",
    "                        sameContract_ = True)\n",
    "    df = api_.hist_data.copy(deep = True)\n",
    "    start_day_ = date_ - datetime.timedelta(hours = 6.5, minutes = 1)\n",
    "    df = df[pd.to_datetime(df['date']) >= start_day_]\n",
    "    \n",
    "    if df.shape[0] == 391:\n",
    "        ind = []\n",
    "        minutes_away_from_strike_helper = [] \n",
    "        for i in range(df.shape[0]):\n",
    "            diffed = strikes_ - df.close.iloc[i]\n",
    "            diffed_high = strikes_ - df.high.iloc[i] # only if high of the minute\n",
    "            diffed_low = strikes_ - df.low.iloc[i] # and the low of the minute is more than a $1 away\n",
    "            ind_candidate = np.abs(diffed).argmin()\n",
    "            if diffed[ind_candidate] <= 0:\n",
    "                ind_candidate += 1\n",
    "            ind.append(ind_candidate)\n",
    "            val = int((np.all(np.abs(diffed_low) > 1)) & (np.all(np.abs(diffed_high) > 1))) # more than a $1 away\n",
    "            minutes_away_from_strike_helper.append(val)\n",
    "        \n",
    "        \n",
    "        ind = np.array(ind)\n",
    "        helper_ind = ind[1:] - ind[:-1]\n",
    "        total_times_crossed_strike = int(sum(helper_ind != 0))\n",
    "        \n",
    "        # minutes away from a strike\n",
    "        minutes_away_from_strike = np.sum(np.array(minutes_away_from_strike_helper))\n",
    "        minutes_away_first_60 = np.sum(np.array(minutes_away_from_strike_helper)[:60])\n",
    "        minutes_away_second_60 = np.sum(np.array(minutes_away_from_strike_helper)[60:120])\n",
    "        minutes_away_third_60 = np.sum(np.array(minutes_away_from_strike_helper)[120:180])\n",
    "        minutes_away_fourth_60 = np.sum(np.array(minutes_away_from_strike_helper)[180:240])\n",
    "        minutes_away_fifth_60 = np.sum(np.array(minutes_away_from_strike_helper)[240:300])\n",
    "        minutes_away_sixth_60 = np.sum(np.array(minutes_away_from_strike_helper)[300:360])\n",
    "        minutes_away_final_30 = np.sum(np.array(minutes_away_from_strike_helper)[360:])\n",
    "        \n",
    "        # minutes away 10.30 to 13.30\n",
    "        minutes_away_1030_130 = np.sum(np.array(minutes_away_from_strike_helper)[60:240])\n",
    "        \n",
    "        # minutes away 11.30 to 13.30\n",
    "        minutes_away_1130_130 = np.sum(np.array(minutes_away_from_strike_helper)[120:240])\n",
    "        \n",
    "        # minutes away 10.30 to 16.00\n",
    "        minutes_away_1030_1600 = np.sum(np.array(minutes_away_from_strike_helper)[60:])\n",
    "        \n",
    "        # minutes away 11.30 to 16.00\n",
    "        minutes_away_1130_1600 = np.sum(np.array(minutes_away_from_strike_helper)[120:])\n",
    "        \n",
    "        # =================================\n",
    "        # This section is about in the money minutes\n",
    "        # Of course with time memory, meaning with regard to strikes that have already passes \n",
    "        # \n",
    "        \n",
    "        # 1030 to 1600\n",
    "        stock_high = np.max(df.high[:60]) \n",
    "        stock_low = np.min(df.low[:60])\n",
    "        strikes_crossed = strikes_[np.where((strikes_ >= stock_low) & (strikes_ <= stock_high))]\n",
    "        strikes_crossed = np.tile(strikes_crossed, (df.shape[0]-60, 1))\n",
    "        vals_high = df.high[60:].values\n",
    "        vals_low = df.low[60:].values\n",
    "        vals_high.shape = (391 - 60, 1)\n",
    "        vals_low.shape = (391 - 60, 1)\n",
    "        distance_high_post_1030 = np.abs(strikes_crossed - vals_high)\n",
    "        distance_low_post_1030 = np.abs(strikes_crossed - vals_low)\n",
    "        minutes_away_high_strikes_post_1030 = np.prod(distance_high_post_1030 > 1, axis = 1)\n",
    "        minutes_away_low_strikes_post_1030 = np.prod(distance_low_post_1030 > 1, axis = 1)\n",
    "        minutes_away_strikes_post_1030 = \\\n",
    "        np.sum(minutes_away_high_strikes_post_1030 * minutes_away_low_strikes_post_1030)\n",
    "        \n",
    "\n",
    "        # 1130 to 1600\n",
    "        stock_high = np.max(df.high[:120]) \n",
    "        stock_low = np.min(df.low[:120])\n",
    "        strikes_crossed = strikes_[np.where((strikes_ >= stock_low) & (strikes_ <= stock_high))]\n",
    "        strikes_crossed = np.tile(strikes_crossed, (df.shape[0]-120, 1))\n",
    "        vals_high = df.high[120:].values\n",
    "        vals_low = df.low[120:].values\n",
    "        vals_high.shape = (391 - 120, 1)\n",
    "        vals_low.shape = (391 - 120, 1)\n",
    "        distance_high_post_1130 = np.abs(strikes_crossed - vals_high)\n",
    "        distance_low_post_1130 = np.abs(strikes_crossed - vals_low)\n",
    "        minutes_away_high_strikes_post_1130 = np.prod(distance_high_post_1130 > 1, axis = 1)\n",
    "        minutes_away_low_strikes_post_1130 = np.prod(distance_low_post_1130 > 1, axis = 1)\n",
    "        minutes_away_strikes_post_1130 = \\\n",
    "        np.sum(minutes_away_high_strikes_post_1130 * minutes_away_low_strikes_post_1130)\n",
    "\n",
    "        # 1230 to 1600\n",
    "        stock_high = np.max(df.high[:180]) \n",
    "        stock_low = np.min(df.low[:180])\n",
    "        strikes_crossed = strikes_[np.where((strikes_ >= stock_low) & (strikes_ <= stock_high))]\n",
    "        strikes_crossed = np.tile(strikes_crossed, (df.shape[0]-180, 1))\n",
    "        vals_high = df.high[180:].values\n",
    "        vals_low = df.low[180:].values\n",
    "        vals_high.shape = (391 - 180, 1)\n",
    "        vals_low.shape = (391 - 180, 1)\n",
    "        distance_high_post_1230 = np.abs(strikes_crossed - vals_high)\n",
    "        distance_low_post_1230 = np.abs(strikes_crossed - vals_low)\n",
    "        minutes_away_high_strikes_post_1230 = np.prod(distance_high_post_1230 > 1, axis = 1)\n",
    "        minutes_away_low_strikes_post_1230 = np.prod(distance_low_post_1230 > 1, axis = 1)\n",
    "        minutes_away_strikes_post_1230 = \\\n",
    "        np.sum(minutes_away_high_strikes_post_1230 * minutes_away_low_strikes_post_1230)\n",
    "        \n",
    "        # 130 to 1600\n",
    "        stock_high = np.max(df.high[:240]) \n",
    "        stock_low = np.min(df.low[:240])\n",
    "        strikes_crossed = strikes_[np.where((strikes_ >= stock_low) & (strikes_ <= stock_high))]\n",
    "        strikes_crossed = np.tile(strikes_crossed, (df.shape[0]-240, 1))\n",
    "        vals_high = df.high[240:].values\n",
    "        vals_low = df.low[240:].values\n",
    "        vals_high.shape = (391 - 240, 1)\n",
    "        vals_low.shape = (391 - 240, 1)\n",
    "        distance_high_post_130 = np.abs(strikes_crossed - vals_high)\n",
    "        distance_low_post_130 = np.abs(strikes_crossed - vals_low)\n",
    "        minutes_away_high_strikes_post_130 = np.prod(distance_high_post_130 > 1, axis = 1)\n",
    "        minutes_away_low_strikes_post_130 = np.prod(distance_low_post_130 > 1, axis = 1)\n",
    "        minutes_away_strikes_post_130 = \\\n",
    "        np.sum(minutes_away_high_strikes_post_130 * minutes_away_low_strikes_post_130)\n",
    "        \n",
    "        # 230 to 1600\n",
    "        stock_high = np.max(df.high[:300]) \n",
    "        stock_low = np.min(df.low[:300])\n",
    "        strikes_crossed = strikes_[np.where((strikes_ >= stock_low) & (strikes_ <= stock_high))]\n",
    "        strikes_crossed = np.tile(strikes_crossed, (df.shape[0]-300, 1))\n",
    "        vals_high = df.high[300:].values\n",
    "        vals_low = df.low[300:].values\n",
    "        vals_high.shape = (391 - 300, 1)\n",
    "        vals_low.shape = (391 - 300, 1)\n",
    "        distance_high_post_230 = np.abs(strikes_crossed - vals_high)\n",
    "        distance_low_post_230 = np.abs(strikes_crossed - vals_low)\n",
    "        minutes_away_high_strikes_post_230 = np.prod(distance_high_post_230 > 1, axis = 1)\n",
    "        minutes_away_low_strikes_post_230 = np.prod(distance_low_post_230 > 1, axis = 1)\n",
    "        minutes_away_strikes_post_230 = \\\n",
    "        np.sum(minutes_away_high_strikes_post_230 * minutes_away_low_strikes_post_230)\n",
    "        \n",
    "        # ==============================\n",
    "        # In this section, we look at the same statistics for the ATM strike\n",
    "        # Not, all the strikes passed before.\n",
    "        \n",
    "        # =====> hourly\n",
    "        closest_strike_1030 = strikes_[np.argmin(np.abs(strikes_ - df.close.iloc[60]))]\n",
    "        closest_strike_1130 = strikes_[np.argmin(np.abs(strikes_ - df.close.iloc[120]))]\n",
    "        closest_strike_1230 = strikes_[np.argmin(np.abs(strikes_ - df.close.iloc[180]))]\n",
    "        closest_strike_130 = strikes_[np.argmin(np.abs(strikes_ - df.close.iloc[240]))]\n",
    "        closest_strike_230 = strikes_[np.argmin(np.abs(strikes_ - df.close.iloc[300]))]\n",
    "\n",
    "        minutes_away_from_atm_1030 = \\\n",
    "        np.sum((np.abs(df.high[60:120] - closest_strike_1030) > 1) & (np.abs(df.low[60:120] - closest_strike_1030) > 1))\n",
    "        minutes_away_from_atm_1130 = \\\n",
    "        np.sum((np.abs(df.high[120:180] - closest_strike_1130) > 1) & (np.abs(df.low[120:180] - closest_strike_1130) > 1))\n",
    "        minutes_away_from_atm_1230 = \\\n",
    "        np.sum((np.abs(df.high[180:240] - closest_strike_1230) > 1) & (np.abs(df.low[180:240] - closest_strike_1230) > 1))\n",
    "        minutes_away_from_atm_130 = \\\n",
    "        np.sum((np.abs(df.high[240:300] - closest_strike_130) > 1) & (np.abs(df.low[240:300] - closest_strike_130) > 1))\n",
    "        minutes_away_from_atm_230 = \\\n",
    "        np.sum((np.abs(df.high[300:360] - closest_strike_230) > 1) & (np.abs(df.low[300:360] - closest_strike_230) > 1))\n",
    "\n",
    "        # =======> multiple hrs\n",
    "        minutes_away_from_atm_1030_130 = \\\n",
    "        np.sum((np.abs(df.high[60:240] - closest_strike_1030) > 1) & (np.abs(df.low[60:240] - closest_strike_1030) > 1))\n",
    "        minutes_away_from_atm_1030_1600 = \\\n",
    "        np.sum((np.abs(df.high[60:390] - closest_strike_1030) > 1) & (np.abs(df.low[60:390] - closest_strike_1030) > 1))\n",
    "        minutes_away_from_atm_130_1600 = \\\n",
    "        np.sum((np.abs(df.high[240:390] - closest_strike_130) > 1) & (np.abs(df.low[240:390] - closest_strike_130) > 1))\n",
    "        \n",
    "        \n",
    "        # strike crosses over time\n",
    "        if total_times_crossed_strike != 0:\n",
    "            first_60 = float(sum(helper_ind[:60] != 0))\n",
    "            second_60 = float(sum(helper_ind[60:120] != 0))\n",
    "            third_60 = float(sum(helper_ind[120:180] != 0))\n",
    "            fourth_60 = float(sum(helper_ind[180:240] != 0))\n",
    "            fifth_60 = float(sum(helper_ind[240:300] != 0))\n",
    "            sixth_60 = float(sum(helper_ind[300:360] != 0))\n",
    "            final_30 = float(sum(helper_ind[360:] != 0))\n",
    "        else:\n",
    "            first_60 = 0.0\n",
    "            second_60 = 0.0\n",
    "            third_60 = 0.0\n",
    "            fourth_60 = 0.0\n",
    "            fifth_60 = 0.0\n",
    "            sixth_60 = 0.0\n",
    "            final_30 = 0.0\n",
    "            \n",
    "        \n",
    "        diffed = strikes_ - df.close[df.shape[0]-1]\n",
    "        argmin = np.abs(diffed).argmin()\n",
    "        how_close_to_strike_at_expiration = diffed[argmin] \n",
    "        \n",
    "        last_interval = strikes_[ind_candidate] - strikes_[ind_candidate - 1]\n",
    "\n",
    "        length_of_dataframe = df.shape[0] \n",
    "        \n",
    "        high_low_over_close_percent = (df.high.max() - df.low.min())/df.close[df.shape[0]-1] * 100\n",
    "        \n",
    "        # unique strike crosses\n",
    "        strike_crosses = len(np.unique(ind))-1 \n",
    "        strike_crosses_first_60 = len(np.unique(ind[:60]))-1 \n",
    "        strike_crosses_second_60 = len(np.unique(ind[60:120]))-1 \n",
    "        strike_crosses_third_60 = len(np.unique(ind[120:180]))-1 \n",
    "        strike_crosses_fourth_60 = len(np.unique(ind[180:240]))-1 \n",
    "        strike_crosses_fifth_60 = len(np.unique(ind[240:300]))-1 \n",
    "        strike_crosses_sixth_60 = len(np.unique(ind[300:360]))-1 \n",
    "        strike_crosses_final_30 = len(np.unique(ind[360:]))-1 \n",
    "        \n",
    "        # unique strike crosses between close and 10.30/11.30/12.30/1.30/2.30\n",
    "        strike_crosses_1030_close = len(np.unique(ind[60:]))-1\n",
    "        strike_crosses_1130_close = len(np.unique(ind[120:]))-1\n",
    "        strike_crosses_1230_close = len(np.unique(ind[180:]))-1\n",
    "        strike_crosses_130_close = len(np.unique(ind[240:]))-1\n",
    "        strike_crosses_230_close = len(np.unique(ind[300:]))-1\n",
    "        \n",
    "        # unique strike crosses from 1030/1130 to 1.30\n",
    "        strike_crosses_1030_130 = len(np.unique(ind[60:240]))-1\n",
    "        strike_crosses_1130_130 = len(np.unique(ind[120:240]))-1\n",
    "        \n",
    "        # mid-day prices\n",
    "        open_price = df.open.iloc[0] \n",
    "        ten_thirty_price = df.close.iloc[60]\n",
    "        eleven_thirty_price = df.close.iloc[120]\n",
    "        twelve_thirty_price = df.close.iloc[180]\n",
    "        one_thirty_price = df.close.iloc[240]\n",
    "        two_thirty_price = df.close.iloc[300]\n",
    "        close_price = df.close.iloc[df.shape[0]-1]\n",
    "        \n",
    "        # return from close to 10.30\n",
    "        ret_close_ten_thirty_percent = float(df.close.iloc[390] - df.close.iloc[60])/df.close.iloc[60] * 100\n",
    "        \n",
    "        # return from close to 1.30\n",
    "        ret_close_one_thirty_percent = float(df.close.iloc[390] - df.close.iloc[240])/df.close.iloc[240] * 100\n",
    "        \n",
    "        # Variance of return by hours\n",
    "        annual_var_first_60_percent = np.var(np.log(np.array(df.close.iloc[1:60])/np.array(df.close.iloc[:59]))) * 25200 * 6.5 \n",
    "        annual_var_second_60_percent = np.var(np.log(np.array(df.close.iloc[61:120])/np.array(df.close.iloc[60:119]))) * 25200 * 6.5 \n",
    "        annual_var_third_60_percent = np.var(np.log(np.array(df.close.iloc[121:180])/np.array(df.close.iloc[120:179]))) * 25200 * 6.5 \n",
    "        annual_var_fourth_60_percent = np.var(np.log(np.array(df.close.iloc[181:240])/np.array(df.close.iloc[180:239]))) * 25200 * 6.5 \n",
    "        annual_var_fifth_60_percent = np.var(np.log(np.array(df.close.iloc[241:300])/np.array(df.close.iloc[240:299]))) * 25200 * 6.5 \n",
    "        annual_var_sixth_60_percent = np.var(np.log(np.array(df.close.iloc[301:360])/np.array(df.close.iloc[300:359]))) * 25200 * 6.5 \n",
    "        annual_var_final_30_percent = np.var(np.log(np.array(df.close.iloc[361:390])/np.array(df.close.iloc[360:389]))) * 25200 * 6.5 * 2 \n",
    "        \n",
    "        del api_\n",
    "        return tuple([date_,\n",
    "                      total_times_crossed_strike, \n",
    "                      first_60,\n",
    "                      second_60,\n",
    "                      third_60,\n",
    "                      fourth_60,\n",
    "                      fifth_60,\n",
    "                      sixth_60,\n",
    "                      final_30,\n",
    "                      strike_crosses,\n",
    "                      strike_crosses_first_60,\n",
    "                      strike_crosses_second_60,\n",
    "                      strike_crosses_third_60,\n",
    "                      strike_crosses_fourth_60,\n",
    "                      strike_crosses_fifth_60,\n",
    "                      strike_crosses_sixth_60,\n",
    "                      strike_crosses_final_30,\n",
    "                      strike_crosses_1030_close,\n",
    "                      strike_crosses_1130_close,\n",
    "                      strike_crosses_1230_close,\n",
    "                      strike_crosses_130_close,\n",
    "                      strike_crosses_230_close,\n",
    "                      strike_crosses_1030_130,\n",
    "                      strike_crosses_1130_130,\n",
    "                      minutes_away_from_strike,\n",
    "                      minutes_away_first_60,\n",
    "                      minutes_away_second_60,\n",
    "                      minutes_away_third_60,\n",
    "                      minutes_away_fourth_60,\n",
    "                      minutes_away_fifth_60,\n",
    "                      minutes_away_sixth_60,\n",
    "                      minutes_away_final_30,\n",
    "                      minutes_away_1030_130,\n",
    "                      minutes_away_1130_130,\n",
    "                      minutes_away_1030_1600,\n",
    "                      minutes_away_1130_1600,\n",
    "                      minutes_away_strikes_post_1030,\n",
    "                      minutes_away_strikes_post_1130,\n",
    "                      minutes_away_strikes_post_1230,\n",
    "                      minutes_away_strikes_post_130,\n",
    "                      minutes_away_strikes_post_230,\n",
    "                      minutes_away_from_atm_1030,\n",
    "                      minutes_away_from_atm_1130,\n",
    "                      minutes_away_from_atm_1230,\n",
    "                      minutes_away_from_atm_130,\n",
    "                      minutes_away_from_atm_230,\n",
    "                      minutes_away_from_atm_1030_130,\n",
    "                      minutes_away_from_atm_1030_1600,\n",
    "                      minutes_away_from_atm_130_1600,\n",
    "                      high_low_over_close_percent,\n",
    "                      how_close_to_strike_at_expiration,\n",
    "                      last_interval,\n",
    "                      open_price,\n",
    "                      ten_thirty_price,\n",
    "                      eleven_thirty_price,\n",
    "                      twelve_thirty_price,\n",
    "                      one_thirty_price,\n",
    "                      two_thirty_price,\n",
    "                      close_price,\n",
    "                      ret_close_ten_thirty_percent,\n",
    "                      ret_close_one_thirty_percent,\n",
    "                      annual_var_first_60_percent,\n",
    "                      annual_var_second_60_percent,\n",
    "                      annual_var_third_60_percent,\n",
    "                      annual_var_fourth_60_percent,\n",
    "                      annual_var_fifth_60_percent,\n",
    "                      annual_var_sixth_60_percent,\n",
    "                      annual_var_final_30_percent,\n",
    "                      length_of_dataframe])\n",
    "    else:\n",
    "        print 'DataFrame had an unusual size'\n",
    "        return tuple(np.repeat(np.NaN, 69))\n",
    "    \n",
    "    \n",
    "# A function to get the implied vol every minute\n",
    "def get_ivol_minutebar_from_ib(ticker_, date_, how_many_weeks_):\n",
    "    \"\"\"\n",
    "    The function returns a dictionary of specified dates as keys and a dataframe of minutes and clsing implied vol as \n",
    "    values. There is a few things to notice here. \n",
    "    1) IB calculated the implied vol. This is tricky. \n",
    "    2) We can go far back as many weeks as we want.\n",
    "    \n",
    "    -----\n",
    "    ticker_: A ticker for the stock we are considering. Has to be a string.\n",
    "    date_: the last friday which we want to consider. A datetime object.\n",
    "    how_many_weeks_: how many weeks we want to go back. An integer\n",
    "    \n",
    "    \"\"\"\n",
    "    api_ = IB_PY()\n",
    "    cont = api_.make_contract(symbol = ticker_, secType = 'STK', currency = 'USD', exchange = 'SMART')\n",
    "    out = dict()\n",
    "    for i in range(how_many_weeks_):\n",
    "        api_.get_historical_data(cont, barSizeSetting_= '1 min', \n",
    "                            durationStr_= '1 D', \n",
    "                            whatToShow_= 'OPTION_IMPLIED_VOLATILITY', \n",
    "                            endDateTime_= date_, \n",
    "                            sameContract_ = True)\n",
    "        df = api_.hist_data.copy(deep = True)\n",
    "        start_day_ = date_ - datetime.timedelta(hours = 6.5, minutes = 1)\n",
    "        df = df[df['date'] >= start_day_]\n",
    "        out_df = pd.DataFrame(columns = ['close'])\n",
    "        out_df['close'] = df.loc[:,'close'].copy(deep = True)\n",
    "        out_df.index = df.date.apply(lambda x: str(x)[11:16])\n",
    "        out_df.index.names = ['time']\n",
    "        out[date_] = out_df\n",
    "        date_ = date_ - datetime.timedelta(days = 7)\n",
    "        \n",
    "    return out\n",
    "# A function to get the price every minute\n",
    "def get_prices_minutebar_from_ib(ticker_, date_, how_many_weeks_, whatToShow_):\n",
    "    \"\"\"\n",
    "    The function returns a dictionary of specified dates as keys and a dataframe of minutes and specified prices as \n",
    "    values. There is a few things to notice here.     \n",
    "    -----\n",
    "    ticker_: A ticker for the stock we are considering. Has to be a string.\n",
    "    date_: the last friday which we want to consider. A datetime object.\n",
    "    how_many_weeks_: how many weeks we want to go back. An integer\n",
    "    whatToShow_: should be 'MIDPOINT'/'BID'/'ASK'/'TRADES'/'BID_ASK'. A string. \n",
    "    \n",
    "    \"\"\"\n",
    "    api_ = IB_PY()\n",
    "    cont = api_.make_contract(symbol = ticker_, secType = 'STK', currency = 'USD', exchange = 'SMART')\n",
    "    out = dict()\n",
    "    for i in range(how_many_weeks_):\n",
    "        api_.get_historical_data(cont, barSizeSetting_= '1 min', \n",
    "                            durationStr_= '1 D', \n",
    "                            whatToShow_= whatToShow_, \n",
    "                            endDateTime_= date_, \n",
    "                            sameContract_ = True)\n",
    "        df = api_.hist_data.copy(deep = True)\n",
    "        start_day_ = date_ - datetime.timedelta(hours = 6.5, minutes = 1)\n",
    "        df = df[df['date'] >= start_day_]\n",
    "        out_df = pd.DataFrame(columns = ['close'])\n",
    "        out_df['close'] = df.loc[:,'close'].copy(deep = True)\n",
    "        out_df.index = df.date.apply(lambda x: str(x)[11:16])\n",
    "        out_df.index.names = ['time']\n",
    "        out[date_] = out_df\n",
    "        date_ = date_ - datetime.timedelta(days = 7)\n",
    "        \n",
    "    return out \n",
    "\n",
    "#=============================\n",
    "def iter_expiration_stats(ticker, end_date, strikes, weeks, ib_whatToShow):\n",
    "    \"\"\"\n",
    "    This function facilitates the data aggregation from ib. Loops on all the dates\n",
    "    \n",
    "    ticker: ticker of the stock. string. \n",
    "    end_date: a datetime object. last day we are interested in.\n",
    "    strikes: strikes related to the stock. A numpy array.\n",
    "    weeks: an integer. how many weeks we are going back.\n",
    "    ib_whatToShow: a string. what do we what from ib. \n",
    "    \n",
    "    \"\"\"\n",
    "    stats = np.empty((0, 69))\n",
    "    for i in range(weeks):\n",
    "        res = expiration_stats(ticker_ = ticker, \n",
    "                               date_ = end_date, \n",
    "                               strikes_ = strikes,\n",
    "                               ib_whatToShow_ = ib_whatToShow)\n",
    "        stats = np.vstack((stats, np.array(res)))\n",
    "        end_date = end_date - datetime.timedelta(days = 7)\n",
    "        time.sleep(1)\n",
    "    # converting it to a dataframe\n",
    "    df_stats = pd.DataFrame(data = stats[:,1:], \n",
    "                            columns = ['total_strike_crosses', 'first_60', 'second_60', 'third_60', 'fourth_60', \\\n",
    "                                    'fifth_60', 'sixth_60', 'final_30', \\\n",
    "                                    'unique_strike_crosses', 'unique_first_60', 'unique_second_60', 'unique_third_60', \\\n",
    "                                    'unique_fourth_60', 'unique_fifth_60', 'unique_sixth_60', 'unique_final_30', \\\n",
    "                                    'unique_strike_1030_close', 'unique_strike_1130_close', \\\n",
    "                                    'unique_strike_1230_close', 'unique_strike_130_close', 'unique_strike_230_close',\\\n",
    "                                    'unique_strike_1030_130', 'unique_strike_1130_130',\\\n",
    "                                    'minutes_one_dollar_away_from_strike', \\\n",
    "                                    'minutes_away_first_60', 'minutes_away_second_60', 'minutes_away_third_60', \\\n",
    "                                    'minutes_away_fourth_60', 'minutes_away_fifth_60', 'minutes_away_sixth_60', \\\n",
    "                                    'minutes_away_final_30', \\\n",
    "                                    'minutes_away_1030_130', 'minutes_away_1130_130', 'minutes_away_1030_1600', \\\n",
    "                                    'minutes_away_1130_1600', \\\n",
    "                                    'minutes_away_post_1030', 'minutes_away_post_1130', 'minutes_away_post_1230', \\\n",
    "                                    'minutes_away_post_130', 'minutes_away_post_230', \\\n",
    "                                    'minutes_away_atm_1030', 'minutes_away_atm_1130', 'minutes_away_atm_1230', \\\n",
    "                                    'minutes_away_atm_130', 'minutes_away_atm_230', 'minutes_away_atm_1030_130', \\\n",
    "                                    'minutes_away_atm_1030_1600', 'minutes_away_atm_130_1600', \\\n",
    "                                    'high_low_over_close_percent', 'distance_strike_at_expiration', 'last_gap_between_strikes',\n",
    "                                    'open_price', 'ten_thirty_price', 'eleven_thirty_price', \\\n",
    "                                    'twelve_thirty_price', 'one_thirty_price', 'two_thirty_price', 'close_price', \\\n",
    "                                    'ret_1030_close_percent', 'ret_130_close_percent', \\\n",
    "                                    'annual_var_first_60', 'annual_var_second_60', 'annual_var_third_60', \\\n",
    "                                    'annual_var_fourth_60', 'annual_var_fifth_60', 'annual_var_sixth_60', \\\n",
    "                                    'annual_var_final_30',\n",
    "                                    'total_number_minutes'],\n",
    "                           index = stats[:,0],\n",
    "                            dtype = np.float)\n",
    "    df_stats.sort_index(axis=0, inplace=True)\n",
    "    df_stats.index = pd.to_datetime(df_stats.index)\n",
    "    df_stats = df_stats.loc[pd.notnull(df_stats.index),:]\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
